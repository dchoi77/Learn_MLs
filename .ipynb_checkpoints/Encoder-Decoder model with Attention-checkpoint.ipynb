{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder model with Attention \n",
    "\n",
    "References: \n",
    "* https://github.com/tensorflow/nmt\n",
    "* https://arxiv.org/abs/1508.04025v5\n",
    "\n",
    "<img src=\"images/attention_mechanism.jpg\" style=\"width: 500px;\">\n",
    "\n",
    "At timestep $t$, the decoder computes its output as follows:\n",
    "\n",
    "1. Compute $\\text{score}(\\mathbf{h}_{t},\\overline{\\mathbf{h}}_{s})$ for $s=1,\\ldots,S$, where $\\overline{\\mathbf{h}}_{s}$ are the encoder outputs at timestep $s=1,\\ldots,S$ and $\\mathbf{h}_{t}$ is the hidden state of the decoder (more explicitly, the hidden state of the GRU layer in the decoder) at timestep $t$.\n",
    "\n",
    "    * Note that the hidden state of the decoder is initially set by the hidden state of the encoder at its final timestep. In particular, the encoder units and the decoder units are the same. They will be expressed as `endec_units`. \n",
    "\n",
    "1. Compute the attention weights $\\alpha_{ts}$, the softmax of the scores.\n",
    "\n",
    "1. Compute the context vector: $\\mathbf{c}_{t}=\\sum_{s=1}^{S}\\alpha_{ts}\\overline{\\mathbf{h}}_{s}$.\n",
    "\n",
    "1. Pass the concatenated vector $[\\mathbf{c}_{t};\\mathbf{e}_{t}]$ to the decoder.GRU, $\\mathbf{e}_{t}$ is the embedding output of the given input to the decoder at timestep $t$.\n",
    "\n",
    "1. Pass the GRU output to a dense layer whose output dimension is decoder\\_vocab\\_size.\n",
    "\n",
    "The following shows two methods of computing scores:\n",
    "\n",
    "* $\\text{score}(\\mathbf{h}_{t},\\overline{\\mathbf{h}}_{s})=\\mathbf{h}_{t}^{T}\\mathbf{W}\\overline{\\mathbf{h}}_{s}$\n",
    "(Luong's multiplicative style)\n",
    "\n",
    "* $\\text{score}(\\mathbf{h}_{t},\\overline{\\mathbf{h}}_{s})=\\mathbf{v}_{a}^{T}\\tanh\\left(\\mathbf{W}_{1}\\mathbf{h}_{t}+\\mathbf{W}_{2}\\overline{\\mathbf{h}}_{s}\\right)$\n",
    "(Bahdanau's additive style)\n",
    "\n",
    "__Encoder__:\n",
    "\n",
    "* The encoder consists of an embedding layer and a GRU layer. Note that it doesn't have a dense layer contrary to the decoder, since the encoder-decoder combined is the whole model.\n",
    "\n",
    "* If x is a batch of shape (batch_size, seq_length), then encoder(x) returns a tuple (output, state) which is simply the output of the GRU layer, where \n",
    "    * output.shape is (batch_size, seq_length, endec_units) and  \n",
    "    * state.shape is (batch_size, endec_units).\n",
    "\n",
    "* The GRU layer is created with the parameters `return_sequences=True` and `return_state=True`.\n",
    "\n",
    "* Note that  \n",
    "    * if `return_sequences=False` and `return_state=False` (which are by default), GRU returns only output with shape (batch_size, units);\n",
    "    * if `return_sequences=True` and `return_state=False`, GRU returns only output with shape (batch_size, seq_length, units);\n",
    "    * if `return_sequences=True` and `return_state=True`, GRU returns both output and state whose shapes are (batch_size, seq_length, units) and (batch_size, units), respectively.\n",
    "\n",
    "```python\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, \n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "```\n",
    "\n",
    "__BahdanauAttention__:\n",
    "\n",
    "* Recall Bahdanau's additive style:\n",
    "$\\text{score}(\\mathbf{h}_{t},\\overline{\\mathbf{h}}_{s})=\\mathbf{v}_{a}^{T}\\tanh\\left(\\mathbf{W}_{1}\\mathbf{h}_{t}+\\mathbf{W}_{2}\\overline{\\mathbf{h}}_{s}\\right)$\n",
    "\n",
    "* The layer `BahdanauAttention` computes context vector and attention weights. \n",
    "    * inputs: a hidden state ($\\mathbf{h}_t$) of the decoder, encoder outputs ($\\overline{\\mathbf{h}}_{s}$s)\n",
    "    * outputs: context vector, attention weights\n",
    "\n",
    "* The parameter `units` in `init()` is the output dimension of both $\\mathbf{W}_{1}$ and $\\mathbf{W}_{2}$. It is independent of `endec_units`, but `units` is set to `endec_units` as shown in init() of the decoder class. Moreover, the last dimensions of $\\mathbf{h}_t$ and $\\overline{\\mathbf{h}}_{s}$s are also independent to each other in the Bahdanau's additive formula, but they are set to be the same in this example.\n",
    "\n",
    "* The parameter `query` in `call()` is $\\mathbf{h}_t$. Its shape is (batch_size, endec_units).\n",
    "\n",
    "* The parameter `values` in `call()` is $\\overline{\\mathbf{h}}_{s}$s. Its shape is (batch_size, enc_seq_length, endec_units).\n",
    "\n",
    "* The output `context_vector` has shape of (batch_size, endec_units). \n",
    "\n",
    "* The output `attention_weights` has shape of (batch_size, enc_seq_length, 1).\n",
    "\n",
    "```python\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        # query.shape: (batch_size, endec_units)\n",
    "        # values.shape: (batch_size, enc_seq_length, endec_units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(tf.expand_dims(query,1)) + self.W2(values)))\n",
    "        # score.shape: (batch_size, enc_seq_length, 1)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # attention_weights.shape: (batch_size, enc_seq_length, 1)\n",
    "        \n",
    "        context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n",
    "        # context_vector.shape: (batch_size, endec_units)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "```\n",
    "\n",
    "__Decoder__:\n",
    "\n",
    "```python\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sze = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, \n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # x.shape: (batch_size, 1, dec_seq_length)\n",
    "        # hidden.shape: (batch_size, endec_units)\n",
    "        # enc_output.sape: (batch_size, enc_seq_length, endec_units)\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # context_vector.shape: (batch_size, endec_units)\n",
    "        # attention_weights.shape: (batch_size, enc_seq_length, 1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # x.shape: (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # x.shape: (batch_size, 1, endec_units + embedding_dim)\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        # output.shape = (batch_size, 1, endec_units)\n",
    "        # state.shape = (batch_size, endec_units)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # output.shape = (batch_size, endec_units)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        # output.shape = (batch_size, vocab_size)\n",
    "        \n",
    "        return output, state, attention_weights \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
