{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Decomposition\n",
    "\n",
    "* Additive model: $y(t) = \\text{Level} + \\text{Trend} + \\text{Seasonality} + \\text{Noise} $\n",
    "\n",
    "\n",
    "* Multiplicative model: $y(t) = \\text{Level} \\times \\text{Trend}  \\times \\text{Seasonality}  \\times \\text{Noise} $\n",
    "\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(x, model='additive')\n",
    "# x is a pandas object with a timeseries index with a freq not set to None.\n",
    "# If x is not a pandas object, freq= should be given in seasonal_decompose().\n",
    "\n",
    "result.plot()\n",
    "\n",
    "# We can get the following data:\n",
    "result.observed\n",
    "result.trend\n",
    "result.reasonal\n",
    "result.resid\n",
    "result.nobs\n",
    "```\n",
    "\n",
    "\n",
    "## Detrending\n",
    "\n",
    "* By differencing: $\\nabla x_t = x_t - x_{t-1}$, more generally, $\\nabla^d x_t = (1-B)^d x_t$, where $B$ is the backshift operator. \n",
    "\n",
    "Example. For a random walk model given as $x_t = x_{t-1} + w_t$ with $w_t\\sim N(0,\\sigma^2)$, we have $\\nabla x_t = x_t - x_{t-1} = w_t$.\n",
    "\n",
    "* By fitting a model: If a model's prediction of $x_t$ is $\\hat{x}_t$, $x_t - \\hat{x}_t$ may detrend the time series.\n",
    "\n",
    "\n",
    "## Deseasonalizing\n",
    "\n",
    "* By differencing: $x_t - x_{t-p}$, where $p$ is a constant depending on the seasonal length\n",
    "\n",
    "    We may resample the time series for a stable result. For example, if $x$ is a temperature dataset measured daily, we can apply the above differencing method with $p=12$ after making a monthly dataset: \n",
    "    ```\n",
    "    x = x.resample('M').mean()\n",
    "    ```\n",
    "    \n",
    "* By fitting a model: If a model's prediction of $x_t$ is $\\hat{x}_t$, $x_t - \\hat{x}_t$ may deseasonalize the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Noise\n",
    "\n",
    "A time series is white noise if the variables are independent and identically distributed with a mean of zero.\n",
    "\n",
    "If the variance changes over time or if values correlate with lag values (we can use `pandas.plotting.autocorrelation_plot()`), the time series is not white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRegressive (AR) model\n",
    "\n",
    "AR(p) = an autoregressive model of order p\n",
    "\n",
    "$X_t = c + \\varphi_1 X_{t-1} + \\cdots + \\varphi_p X_{t-p} + \\epsilon_t = c + (\\varphi_1 B + \\cdots + \\varphi_p B^p)X_t + \\epsilon_t$, where $B$ is the backshift operator. \n",
    "\n",
    "Equivalently, $\\phi[B]X_t = c + \\epsilon_t$, where $\\phi[B] = 1 - \\varphi_1 B - \\cdots -\\varphi_p B^p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving-Average (MA) model\n",
    "\n",
    "MA(q) = an moving average model of order q\n",
    "\n",
    "$X_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\cdots +\\theta_q \\epsilon_{t-q} = \\mu + (1 + \\theta_1 B + \\cdots +\\theta_q B^q) \\epsilon_t$, where $B$ is the backshift operator. \n",
    "\n",
    "Contrary to the AR model, the finite MA model is always stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRegressive–Moving-Average (ARMA) model\n",
    "\n",
    "ARMA(p,q) = an model with p autoregressive terms and q moving-average terms\n",
    "\n",
    "$X_t = c+ \\epsilon_t  + (\\varphi_1 B + \\cdots + \\varphi_p B^p)X_t + (\\theta_1 B + \\cdots +\\theta_q B^q) \\epsilon_t$\n",
    "\n",
    "The error terms $\\epsilon_t$ are assumed to be i.i.d. sampled from $N(0,\\sigma^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dickey–Fuller test\n",
    "\n",
    "The Dickey–Fuller test tests the null hypothesis that a unit root is present in an autoregressive model.\n",
    "\n",
    "AR(1) model is $x_t = \\rho x_{t-1} + \\epsilon_t$. A unit root is present if $\\rho=1$. \n",
    "\n",
    "The model can be written as $\\Delta x_t = \\gamma x_{t-1} + \\epsilon_t$, where $\\gamma = \\rho -1$. \n",
    "\n",
    "Since the test is done over the residual term rather than raw data, it is not possible to use standard t-distribution to provide critical values. This statistic $t$ has a specific distribution known as the Dickey–Fuller table.\n",
    "\n",
    "There are three main versions of the test:\n",
    "\n",
    "1. Test for a unit root: $\\Delta x_t = \\gamma x_{t-1} + \\epsilon_t$\n",
    "1. Test for a unit root with drift: $\\Delta x_t = \\alpha + \\gamma x_{t-1} + \\epsilon_t$\n",
    "1. Test for a unit root with drift and deterministic time trend: $\\Delta x_t = \\alpha + \\beta t + \\gamma x_{t-1} + \\epsilon_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dickey–Fuller test\n",
    "\n",
    "The testing procedure for the ADF test is the same as for the Dickey–Fuller test but it is applied to the model\n",
    "\n",
    "$\\Delta x_t = \\alpha + \\beta t + \\gamma x_{t-1} + \\delta_1\\Delta x_{t-1} + \\cdots + \\delta_{p-1} \\Delta x_{t-p+1} + \\epsilon_t$\n",
    "\n",
    "The ADF statistic is a negative number. The more negative it is, the stronger the rejection of the hypothesis that there is a unit root at some level of confidence.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# random_walk is a list of numbers.\n",
    "result = adfuller(random_walk)\n",
    "\n",
    "result[0]      # ADF statistic\n",
    "result[1]      # p-value\n",
    "result[4]      # Critical values for the test statistic at the 1 %, 5 %, and 10 % levels. \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
